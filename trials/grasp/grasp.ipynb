{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# GraSP pruning"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T16:49:21.535851Z","iopub.status.busy":"2023-05-16T16:49:21.535445Z","iopub.status.idle":"2023-05-16T16:49:33.619109Z","shell.execute_reply":"2023-05-16T16:49:33.617995Z","shell.execute_reply.started":"2023-05-16T16:49:21.535808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchbearer\n","  Downloading torchbearer-0.5.3-py3-none-any.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchbearer) (2.0.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchbearer) (1.23.5)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchbearer) (4.64.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (4.5.0)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (3.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (3.11.0)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (3.1.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (1.11.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchbearer) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchbearer) (1.3.0)\n","Installing collected packages: torchbearer\n","Successfully installed torchbearer-0.5.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install torchbearer"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T16:49:40.317792Z","iopub.status.busy":"2023-05-16T16:49:40.316724Z","iopub.status.idle":"2023-05-16T16:49:43.863795Z","shell.execute_reply":"2023-05-16T16:49:43.862613Z","shell.execute_reply.started":"2023-05-16T16:49:40.317754Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn.utils import prune\n","import torchvision.transforms as transforms\n","import torchbearer\n","from torch import nn\n","from torch import optim\n","from torch.utils.data import DataLoader, random_split\n","from torchvision.datasets import CIFAR10\n","from torchvision.models import vgg16_bn, vgg19_bn\n","from torchbearer import Trial\n","import numpy as np\n","import random"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T16:49:43.870652Z","iopub.status.busy":"2023-05-16T16:49:43.870030Z","iopub.status.idle":"2023-05-16T16:49:43.883833Z","shell.execute_reply":"2023-05-16T16:49:43.882727Z","shell.execute_reply.started":"2023-05-16T16:49:43.870616Z"},"trusted":true},"outputs":[],"source":["# fix random seed for reproducibility\n","seed = 7\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset Preparation\n","The CIFAR-10 dataset is downloaded and transformed with a batch size of 128, using the same parameters as the source research paper [1]. The training dataset is transformed by random crop followed by horizontal flips."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T16:49:46.506656Z","iopub.status.busy":"2023-05-16T16:49:46.506117Z","iopub.status.idle":"2023-05-16T16:49:56.453644Z","shell.execute_reply":"2023-05-16T16:49:56.452739Z","shell.execute_reply.started":"2023-05-16T16:49:46.506615Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:05<00:00, 28599440.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./cifar-10-python.tar.gz to .\n","Files already downloaded and verified\n"]}],"source":["train_batch_size = 128\n","test_batch_size = 128\n","\n","# convert each image to tensor format\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","# load data\n","trainset = CIFAR10(root='.', train=True, download=True, transform=transform_train)\n","testset = CIFAR10(root='.', train=False, download=True, transform=transform_test)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T16:49:56.455857Z","iopub.status.busy":"2023-05-16T16:49:56.455507Z","iopub.status.idle":"2023-05-16T16:49:56.460883Z","shell.execute_reply":"2023-05-16T16:49:56.460028Z","shell.execute_reply.started":"2023-05-16T16:49:56.455824Z"},"trusted":true},"outputs":[],"source":["# create data loaders\n","trainloader = DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\n","testloader = DataLoader(testset, batch_size=test_batch_size, shuffle=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining Model\n","The default VGG16 model from Pytorch is modified to align with the CIFAR-10 dataset which has 10 output classes."]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:04:59.595332Z","iopub.status.busy":"2023-05-16T17:04:59.594972Z","iopub.status.idle":"2023-05-16T17:05:02.286707Z","shell.execute_reply":"2023-05-16T17:05:02.285758Z","shell.execute_reply.started":"2023-05-16T17:04:59.595301Z"},"trusted":true},"outputs":[{"data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace=True)\n","    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace=True)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace=True)\n","    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace=True)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace=True)\n","  )\n","  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["num_classes = 10\n","\n","model = vgg16_bn()\n","model.features = model.features[:-1]\n","model.avgpool = nn.AvgPool2d(2)\n","model.classifier = nn.Linear(512, num_classes)\n","model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Reinitialised weights using [He initialisation](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_) method for all linear and convolution layers. And using random weight from a uniform distribution for Batch normalization weight with zero bias."]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:05:02.289092Z","iopub.status.busy":"2023-05-16T17:05:02.288728Z","iopub.status.idle":"2023-05-16T17:05:02.392048Z","shell.execute_reply":"2023-05-16T17:05:02.391121Z","shell.execute_reply.started":"2023-05-16T17:05:02.289058Z"},"trusted":true},"outputs":[],"source":["def init_weights(m):\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        # He initialization\n","        nn.init.kaiming_normal_(m.weight)\n","        # Glorot initialization\n","        # nn.init.xavier_normal(m.weight)\n","    elif isinstance(m, torch.nn.BatchNorm2d):\n","        m.weight.data = torch.rand(m.weight.data.shape)\n","        m.bias.data = torch.zeros_like(m.bias.data)\n","\n","model = model.apply(init_weights)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## GraSP Pruning"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:05:04.204009Z","iopub.status.busy":"2023-05-16T17:05:04.202652Z","iopub.status.idle":"2023-05-16T17:05:04.225293Z","shell.execute_reply":"2023-05-16T17:05:04.224321Z","shell.execute_reply.started":"2023-05-16T17:05:04.203962Z"},"trusted":true},"outputs":[],"source":["def data_sampling(trainset):\n","    # Sample 10 data from each class (100 data in total)\n","    s_inputs = []\n","    s_targets = []\n","    samples = next(iter(DataLoader(trainset, batch_size=300, shuffle=True)))\n","    for t in set(trainset.targets):\n","        indices = random.sample([i for i, x in enumerate(samples[1]) if x == t], 10)\n","        s_inputs += [samples[0][i].tolist() for i in indices]\n","        s_targets += [samples[1][i].tolist() for i in indices]\n","\n","    s_inputs = torch.Tensor(np.array(s_inputs))\n","    s_targets = torch.Tensor(np.array(s_targets)).to(torch.long)\n","\n","    print(s_inputs.shape)\n","    print(s_targets.shape)\n","    return s_inputs, s_targets\n","\n","def magnitude_score(model, trainset):\n","    '''calculate pruning score for all prune-able layers\n","        return: {layer: tensor of score for each weight in the layer}'''\n","    # modified from: https://github.com/alecwangcq/GraSP/blob/master/pruner/GraSP.py\n","    T = 200\n","    model.zero_grad()\n","    weights = [weight for name, weight in model.named_parameters() if name.endswith('.weight')]\n","    \n","    # sampling from trainset\n","    s_inputs, s_targets = data_sampling(trainset)\n","    \n","    # compute the Hessian-gradient\n","    outputs = model.forward(s_inputs)/T\n","    loss = F.cross_entropy(outputs, s_targets)\n","    grad_w = list(torch.autograd.grad(loss, weights))\n","\n","    outputs = model.forward(s_inputs)/T\n","    loss = F.cross_entropy(outputs, s_targets)\n","    grad_f = list(torch.autograd.grad(loss, weights, create_graph=True))\n","\n","    z = sum([(gw.data * gf).sum() for gw, gf in zip(grad_w, grad_f)])\n","    z.backward()\n","\n","    scores = {}\n","    for name, weight in model.named_parameters():\n","        if name.endswith('.weight'):\n","            # score is calculated by -weight * Hessian-gradient\n","            scores[name.replace('.weight', '')] = -weight.detach() * weight.grad\n","    return scores\n","\n","def create_mask(model, scores, sparse_ratio, prune_type='min', random_shuffling=False):\n","    # flatted all score to a vector \n","    # modified from: https://github.com/alecwangcq/GraSP/blob/master/pruner/GraSP.py\n","    score_vec = torch.cat([torch.flatten(x) for x in scores.values()])\n","    \n","    # nomalisation \n","    eps = 1e-10\n","    norm_factor = torch.abs(torch.sum(score_vec)) + eps\n","    score_vec.div_(norm_factor)\n","    \n","    # calculate number of parameters to prune\n","    num_prune = np.ceil(len(score_vec) * sparse_ratio).astype(int)\n","    num_keep = (score_vec.shape - num_prune)[0]\n","    print(\"Number of params to prune:\", num_prune)\n","    print(\"Remaining params:\", num_keep)\n","    \n","    if prune_type == 'top':\n","        # prune top k score\n","        threshold = torch.topk(score_vec, num_prune, sorted=True)[0][-1]\n","        print('threshold', threshold.data)\n","    elif prune_type == 'min':\n","        # prune min k score\n","        threshold = torch.topk(score_vec, num_keep, sorted=True)[0][-1]\n","        print('threshold', threshold.data)\n","        \n","    # create mask\n","    masks = {}\n","    named_modules = dict(model.named_modules())\n","    \n","    for m, g in scores.items():\n","        layer = named_modules[m]\n","        if prune_type == 'top':\n","            # prune top k score\n","            masks[layer] = ((g / norm_factor) <= threshold).float()\n","        elif prune_type == 'min':\n","            # prune min k score\n","            masks[layer] = ((g / norm_factor) >= threshold).float()\n","            \n","        if random_shuffling:\n","            ## randomly shuffle weight within each layer\n","            idx = torch.randperm(masks[layer].nelement())\n","            masks[layer] = masks[layer].view(-1)[idx].view(masks[layer].size())\n","            \n","    print('masks', torch.sum(torch.cat([torch.flatten(x == 1) for x in masks.values()])))\n","    return masks\n","\n","def prune_model(model, masks, reinit=False):\n","    if reinit:\n","        # re-initialise weight\n","        model = model.apply(init_weights)\n","\n","    for m in masks.keys():\n","        m = prune.custom_from_mask(m, name='weight', mask=masks[m].data)\n","    \n","    return model"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:05:04.794914Z","iopub.status.busy":"2023-05-16T17:05:04.794290Z","iopub.status.idle":"2023-05-16T17:05:16.563880Z","shell.execute_reply":"2023-05-16T17:05:16.562848Z","shell.execute_reply.started":"2023-05-16T17:05:04.794870Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([100, 3, 32, 32])\n","torch.Size([100])\n","Number of params to prune: 13247828\n","Remaining params: 1471980\n","threshold tensor(-1.0171e-05)\n","masks tensor(1471981)\n"]}],"source":["sparse_ratio = 0.9\n","# for inversion, use prune_type = 'min'\n","prune_type = 'top' # ['top', 'min']\n","random_shuffling = False\n","reinit = False\n","\n","scores = magnitude_score(model, trainset)\n","masks = create_mask(model, scores, sparse_ratio, prune_type, random_shuffling)\n","model = prune_model(model, masks, reinit)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:06:00.872597Z","iopub.status.busy":"2023-05-16T17:06:00.872248Z","iopub.status.idle":"2023-05-16T17:06:00.880182Z","shell.execute_reply":"2023-05-16T17:06:00.879232Z","shell.execute_reply.started":"2023-05-16T17:06:00.872570Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_loss(train_loss, test_loss):\n","    plt.plot(train_loss, label=\"Training data\")\n","    plt.plot(test_loss, label=\"Validation data\")\n","    plt.xlabel(\"Epochs\", fontsize=\"18\")\n","    plt.ylabel(\"Loss\", fontsize=\"18\")\n","    plt.tick_params(axis='both', which='major', labelsize=15)\n","    plt.legend(fontsize=\"15\")\n","    plt.grid()\n","    plt.show();\n","\n","def plot_acc(train_acc, test_acc):\n","    plt.plot(train_acc, label=\"Training data\")\n","    plt.plot(test_acc, label=\"Validation data\")\n","    plt.xlabel(\"Epochs\", fontsize=\"18\")\n","    plt.ylabel(\"Accuracy\", fontsize=\"18\")\n","    plt.tick_params(axis='both', which='major', labelsize=15)\n","    plt.legend(fontsize=\"15\")\n","    plt.grid();"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:06:01.155962Z","iopub.status.busy":"2023-05-16T17:06:01.155584Z","iopub.status.idle":"2023-05-16T17:06:01.162365Z","shell.execute_reply":"2023-05-16T17:06:01.161491Z","shell.execute_reply.started":"2023-05-16T17:06:01.155930Z"},"trusted":true},"outputs":[],"source":["from torchbearer import Callback\n","from torchbearer import callbacks\n","from torchbearer.callbacks import MultiStepLR\n","\n","@callbacks.on_end_epoch\n","def callback(state):\n","    try:\n","        train_loss[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['loss']\n","        train_acc[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['acc']\n","        test_loss[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['val_loss']\n","        test_acc[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['val_acc']\n","    except:\n","        pass"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:06:01.615515Z","iopub.status.busy":"2023-05-16T17:06:01.615163Z","iopub.status.idle":"2023-05-16T17:06:01.625875Z","shell.execute_reply":"2023-05-16T17:06:01.622067Z","shell.execute_reply.started":"2023-05-16T17:06:01.615487Z"},"trusted":true},"outputs":[],"source":["device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","# train the model using cross entropy loss with loss ratio scheduler and SDG optimiser\n","def train_model(model, epochs=80):\n","    model = model.to(device)\n","    loss_function = nn.CrossEntropyLoss()\n","    scheduler = callbacks.MultiStepLR(milestones=[40, 60], gamma=0.1)\n","    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n","\n","    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy'], callbacks=[callback, scheduler]).to(device)\n","    trial.with_generators(trainloader, test_generator=testloader, val_generator=testloader)\n","    trial.run(epochs)\n","    results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n","    print(results)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T17:06:03.163311Z","iopub.status.busy":"2023-05-16T17:06:03.162844Z","iopub.status.idle":"2023-05-16T17:07:40.297126Z","shell.execute_reply":"2023-05-16T17:07:40.296182Z","shell.execute_reply.started":"2023-05-16T17:06:03.163274Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0f067d2f3434b07a064aeb98cb1f095","version_major":2,"version_minor":0},"text/plain":["0/2(t):   0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9348230100064355b30c5463d33aadf8","version_major":2,"version_minor":0},"text/plain":["0/2(v):   0%|          | 0/79 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"940c5021e7d34f2884ad8cbbd5b4e420","version_major":2,"version_minor":0},"text/plain":["1/2(t):   0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23e554c2226d4bd6bca09a839653deec","version_major":2,"version_minor":0},"text/plain":["1/2(v):   0%|          | 0/79 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65bda8d9aa8f44d2ac5f6c3ac2815bcd","version_major":2,"version_minor":0},"text/plain":["0/1(e):   0%|          | 0/79 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'test_loss': 1.0348103046417236, 'test_acc': 0.6349999904632568}\n"]}],"source":["num_epochs = 80\n","\n","# save loss and accuracy during training\n","train_loss = np.zeros(num_epochs)\n","train_acc = np.zeros(num_epochs)\n","test_loss = np.zeros(num_epochs)\n","test_acc = np.zeros(num_epochs)\n","\n","# train model\n","train_model(model, epochs=num_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_loss(train_loss, test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_acc(train_acc, test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), \"./weight.weights\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# References\n","[1] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, and Michael Carbin. Pruning neural net- works at initialization: Why are we missing the mark? In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=Ig-VyQc-MLK"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
