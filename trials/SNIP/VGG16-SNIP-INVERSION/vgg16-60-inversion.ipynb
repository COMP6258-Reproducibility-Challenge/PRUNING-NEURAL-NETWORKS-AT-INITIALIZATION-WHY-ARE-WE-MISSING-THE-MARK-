{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchbearer","metadata":{"id":"aeefabcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.utils.prune as prune\nimport torch.nn.functional as F\nimport torchbearer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nfrom torchvision.models import vgg16_bn, vgg19_bn\nnum_classes = 10\nmodel = vgg16_bn()\nmodel.features = model.features[:-1]\nmodel.avgpool = nn.AvgPool2d(2)\nmodel.classifier = nn.Linear(512, num_classes)","metadata":{"id":"d6d771e8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, torch.nn.BatchNorm2d):\n        m.weight.data = torch.rand(m.weight.data.shape)\n        m.bias.data = torch.zeros_like(m.bias.data)\n\nmodel = model.apply(init_weights)","metadata":{"id":"05694873"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\n\ntrain_batch_size = 128\ntest_batch_size = 128\n\n# convert each image to tensor format\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\n# load data\ntrainset = CIFAR10(root='.', train=True, download=True, transform=transform_train)\ntestset = CIFAR10(root='.', train=False, download=True, transform=transform_test)","metadata":{"id":"c1b6aa1f","outputId":"0d23cd44-f322-4b17-e00e-b7d4544925b3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\n\ntrainloader = DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\n# validloader = DataLoader(valid_data, batch_size=train_batch_size, shuffle=True)\ntestloader = DataLoader(testset, batch_size=test_batch_size, shuffle=False)","metadata":{"id":"5f26ff3a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\n\nsparse_ratio = 0.6\n\ns_inputs = []\ns_targets = []\n\nsamples = next(iter(DataLoader(trainset, batch_size=300, shuffle=True)))\nfor t in set(trainset.targets):\n    indices = random.sample([i for i, x in enumerate(samples[1]) if x == t], 10)\n    s_inputs += [samples[0][i].tolist() for i in indices]\n    s_targets += [samples[1][i].tolist() for i in indices]\n\ns_inputs = torch.Tensor(np.array(s_inputs))\ns_targets = torch.Tensor(np.array(s_targets)).to(torch.long)\n\nprint(s_inputs.shape)\nprint(s_targets.shape)","metadata":{"id":"2b6e47aa","outputId":"bb13505e-6042-4662-b216-e46adca7d9c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nmodel.train()\nmodel.zero_grad()\nweights = [weight for name, weight in model.named_parameters() if name.endswith('.weight')]\n\n# feed sample data to the model\noutputs = model.forward(s_inputs)\nloss = F.cross_entropy(outputs, s_targets).backward()\n# grad_w = list(torch.autograd.grad(loss, weights))\n","metadata":{"id":"9450a455"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = {}\n\nfor name, weight in model.named_parameters():\n    if name.endswith('.weight'):\n        scores[name.replace('.weight', '')] = torch.abs(weight.detach() * weight.grad) ","metadata":{"id":"76234a99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_vec = torch.cat([torch.flatten(x) for x in scores.values()])\nnorm_factor = torch.sum(score_vec)\nscore_vec.div_(norm_factor)","metadata":{"id":"9e62d041","outputId":"132a2c7b-97a9-4543-9968-5096937a0243"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_prune = np.ceil(len(score_vec) * sparse_ratio).astype(int)\nprint(\"Number of params to prune:\", num_prune)\nprint(\"Remaining params:\", score_vec.shape - num_prune)","metadata":{"id":"47405f88","outputId":"2f2f1ef1-4095-4e72-ca5f-76003ae2e08f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_keep = (score_vec.shape - num_prune)[0]\nthreshold = torch.topk(score_vec, num_prune, sorted=True)[0][-1]\nprint(threshold)","metadata":{"id":"19e7441f","outputId":"da199cb1-2ba0-43f9-acba-da17576f52bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"masks = {}\nnamed_modules = dict(model.named_modules())\n\nfor m, g in scores.items():\n    masks[named_modules[m]] = ((g / norm_factor) <= threshold).float()","metadata":{"id":"308c1cef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Masks')\nprint(torch.sum(torch.cat([torch.flatten(x == 1) for x in masks.values()])))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils import prune\n\nfor m in masks.keys():\n    m = prune.custom_from_mask(m, name='weight', mask=masks[m])","metadata":{"id":"945529d7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_loss(train_loss, test_loss):\n    plt.plot(train_loss, label=\"Training data\")\n    plt.plot(test_loss, label=\"Validation data\")\n    plt.xlabel(\"Epochs\", fontsize=\"18\")\n    plt.ylabel(\"Loss\", fontsize=\"18\")\n    plt.tick_params(axis='both', which='major', labelsize=15)\n    plt.legend(fontsize=\"15\")\n    plt.grid()\n    plt.show();\n\ndef plot_acc(train_acc, test_acc):\n    plt.plot(train_acc, label=\"Training data\")\n    plt.plot(test_acc, label=\"Validation data\")\n    plt.xlabel(\"Epochs\", fontsize=\"18\")\n    plt.ylabel(\"Accuracy\", fontsize=\"18\")\n    plt.tick_params(axis='both', which='major', labelsize=15)\n    plt.legend(fontsize=\"15\")\n    plt.grid();","metadata":{"id":"e02ade0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchbearer import Trial","metadata":{"id":"37386ee7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchbearer import Callback\nfrom torchbearer import callbacks\nfrom torchbearer.callbacks import MultiStepLR\n\n@callbacks.on_end_epoch\ndef callback(state):\n    try:\n        train_loss[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['loss']\n        train_acc[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['acc']\n        test_loss[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['val_loss']\n        test_acc[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['val_acc']\n    except:\n        pass","metadata":{"id":"799c028b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, epochs=80):\n    model = model.to(device)\n    loss_function = nn.CrossEntropyLoss()\n    scheduler = callbacks.MultiStepLR(milestones=[40, 60], gamma=0.1)\n    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n\n    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy'], callbacks=[callback, scheduler]).to(device)\n    trial.with_generators(trainloader, test_generator=testloader, val_generator=testloader)\n    trial.run(epochs)\n    results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n    print(results)","metadata":{"id":"iapJOO53hJmY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import optim\n\n\nnum_epochs = 80\n\ntrain_loss = np.zeros(num_epochs)\ntrain_acc = np.zeros(num_epochs)\ntest_loss = np.zeros(num_epochs)\ntest_acc = np.zeros(num_epochs)\n\ntrain_model(model, epochs=num_epochs)","metadata":{"id":"VZNWcE62hJpn","outputId":"8d805031-365a-400d-d6b8-b4b1fb817628"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(train_loss, test_loss)","metadata":{"id":"mGE7DJclhJsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_acc(train_acc, test_acc)","metadata":{"id":"t61CyRYMhJvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save the trained model weights\ntorch.save(model.state_dict(), \"./vgg16-60-inversion.weights\")\n# from google.colab import files\n# files.download('vgg19-90-2.weights')","metadata":{"id":"H_qZBkythJx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}