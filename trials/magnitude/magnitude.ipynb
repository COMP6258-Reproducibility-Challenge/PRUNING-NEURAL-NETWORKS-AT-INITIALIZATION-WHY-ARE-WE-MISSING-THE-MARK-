{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Magnitude pruning","metadata":{}},{"cell_type":"code","source":"!pip install torchbearer","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:19:27.870912Z","iopub.execute_input":"2023-05-16T16:19:27.871313Z","iopub.status.idle":"2023-05-16T16:19:41.923403Z","shell.execute_reply.started":"2023-05-16T16:19:27.871266Z","shell.execute_reply":"2023-05-16T16:19:41.922160Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchbearer\n  Downloading torchbearer-0.5.3-py3-none-any.whl (138 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchbearer) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchbearer) (4.64.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchbearer) (1.23.5)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (3.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (3.11.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchbearer) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchbearer) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchbearer) (1.3.0)\nInstalling collected packages: torchbearer\nSuccessfully installed torchbearer-0.5.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.nn.utils import prune\nimport torchvision.transforms as transforms\nimport torchbearer\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import vgg16_bn, vgg19_bn\nfrom torchbearer import Trial\nimport numpy as np\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:22:37.448313Z","iopub.execute_input":"2023-05-16T16:22:37.448705Z","iopub.status.idle":"2023-05-16T16:22:37.455818Z","shell.execute_reply.started":"2023-05-16T16:22:37.448676Z","shell.execute_reply":"2023-05-16T16:22:37.454924Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 7\ntorch.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:19:47.956981Z","iopub.execute_input":"2023-05-16T16:19:47.957636Z","iopub.status.idle":"2023-05-16T16:19:47.966402Z","shell.execute_reply.started":"2023-05-16T16:19:47.957587Z","shell.execute_reply":"2023-05-16T16:19:47.965173Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Preparation\nThe CIFAR-10 dataset is downloaded and transformed with a batch size of 128, using the same parameters as the source research paper [1]. The training dataset is transformed by random crop followed by horizontal flips.","metadata":{}},{"cell_type":"code","source":"train_batch_size = 128\ntest_batch_size = 128\n\n# convert each image to tensor format\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\n# load data\ntrainset = CIFAR10(root='.', train=True, download=True, transform=transform_train)\ntestset = CIFAR10(root='.', train=False, download=True, transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:24:18.328285Z","iopub.execute_input":"2023-05-16T16:24:18.328682Z","iopub.status.idle":"2023-05-16T16:24:20.117294Z","shell.execute_reply.started":"2023-05-16T16:24:18.328650Z","shell.execute_reply":"2023-05-16T16:24:20.116223Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# create data loaders\ntrainloader = DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\ntestloader = DataLoader(testset, batch_size=test_batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:24:32.247563Z","iopub.execute_input":"2023-05-16T16:24:32.247982Z","iopub.status.idle":"2023-05-16T16:24:32.253515Z","shell.execute_reply.started":"2023-05-16T16:24:32.247948Z","shell.execute_reply":"2023-05-16T16:24:32.251950Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Defining Model\nThe default VGG16 model from Pytorch is modified to align with the CIFAR-10 dataset which has 10 output classes.","metadata":{}},{"cell_type":"code","source":"num_classes = 10\n\nmodel = vgg16_bn()\nmodel.features = model.features[:-1]\nmodel.avgpool = nn.AvgPool2d(2)\nmodel.classifier = nn.Linear(512, num_classes)\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:07.782204Z","iopub.execute_input":"2023-05-16T16:39:07.782659Z","iopub.status.idle":"2023-05-16T16:39:10.127730Z","shell.execute_reply.started":"2023-05-16T16:39:07.782622Z","shell.execute_reply":"2023-05-16T16:39:10.126829Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (26): ReLU(inplace=True)\n    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (36): ReLU(inplace=True)\n    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (39): ReLU(inplace=True)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n  )\n  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (classifier): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"Reinitialised weights using [He initialisation](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_) method for all linear and convolution layers. And using random weight from a uniform distribution for Batch normalization weight with zero bias.","metadata":{}},{"cell_type":"code","source":"def init_weights(m):\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, torch.nn.BatchNorm2d):\n        m.weight.data = torch.rand(m.weight.data.shape)\n        m.bias.data = torch.zeros_like(m.bias.data)\n\nmodel = model.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:10.129519Z","iopub.execute_input":"2023-05-16T16:39:10.130349Z","iopub.status.idle":"2023-05-16T16:39:10.242855Z","shell.execute_reply.started":"2023-05-16T16:39:10.130310Z","shell.execute_reply":"2023-05-16T16:39:10.241763Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"## Magnitude Pruning","metadata":{}},{"cell_type":"code","source":"def magnitude_score(model):\n    '''calculate pruning score for all prune-able layers\n        return: {layer: tensor of score for each weight in the layer}'''\n    scores = {}\n    for name, weight in model.named_parameters():\n        if name.endswith('.weight'):\n            # score of each weight is its magnitude\n            scores[name.replace('.weight', '')] = torch.abs(weight)\n    return scores\n\ndef create_mask(model, scores, sparse_ratio, prune_type='min', random_shuffling=False):\n    # flatted all score to a vector \n    # modified from: https://github.com/alecwangcq/GraSP/blob/master/pruner/GraSP.py\n    score_vec = torch.cat([torch.flatten(x) for x in scores.values()])\n    \n    # nomalisation \n    eps = 1e-10\n    norm_factor = torch.abs(torch.sum(score_vec)) + eps\n    score_vec.div_(norm_factor)\n    \n    # calculate number of parameters to prune\n    num_prune = np.ceil(len(score_vec) * sparse_ratio).astype(int)\n    num_keep = (score_vec.shape - num_prune)[0]\n    print(\"Number of params to prune:\", num_prune)\n    print(\"Remaining params:\", num_keep)\n    \n    if prune_type == 'top':\n        # prune top k score\n        threshold = torch.topk(score_vec, num_prune, sorted=True)[0][-1]\n        print('threshold', threshold.data)\n    elif prune_type == 'min':\n        # prune min k score\n        threshold = torch.topk(score_vec, num_keep, sorted=True)[0][-1]\n        print('threshold', threshold.data)\n        \n    # create mask\n    masks = {}\n    named_modules = dict(model.named_modules())\n    \n    for m, g in scores.items():\n        layer = named_modules[m]\n        if prune_type == 'top':\n            # prune top k score\n            masks[layer] = ((g / norm_factor) <= threshold).float()\n        elif prune_type == 'min':\n            # prune min k score\n            masks[layer] = ((g / norm_factor) >= threshold).float()\n            \n        if random_shuffling:\n            ## randomly shuffle weight within each layer\n            idx = torch.randperm(masks[layer].nelement())\n            masks[layer] = masks[layer].view(-1)[idx].view(masks[layer].size())\n            \n    print('masks', torch.sum(torch.cat([torch.flatten(x == 1) for x in masks.values()])))\n    return masks\n\ndef prune_model(model, masks, reinit=False):\n    if reinit:\n        # re-initialise weight\n        model = model.apply(init_weights)\n\n    for m in masks.keys():\n        m = prune.custom_from_mask(m, name='weight', mask=masks[m].data)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:10.244360Z","iopub.execute_input":"2023-05-16T16:39:10.245301Z","iopub.status.idle":"2023-05-16T16:39:10.261683Z","shell.execute_reply.started":"2023-05-16T16:39:10.245262Z","shell.execute_reply":"2023-05-16T16:39:10.260635Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"sparse_ratio = 0.9\n# for inversion, use prune_type = 'top'\nprune_type = 'min' # ['top', 'min']\nrandom_shuffling = False\nreinit = False\n\nscores = magnitude_score(model)\nmasks = create_mask(model, scores, sparse_ratio, prune_type, random_shuffling)\nmodel = prune_model(model, masks, reinit)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:10.264200Z","iopub.execute_input":"2023-05-16T16:39:10.264805Z","iopub.status.idle":"2023-05-16T16:39:11.924481Z","shell.execute_reply.started":"2023-05-16T16:39:10.264773Z","shell.execute_reply":"2023-05-16T16:39:11.922671Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Number of params to prune: 13247828\nRemaining params: 1471980\nthreshold tensor(1.3925e-07)\nmasks tensor(1471980)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_loss(train_loss, test_loss):\n    plt.plot(train_loss, label=\"Training data\")\n    plt.plot(test_loss, label=\"Validation data\")\n    plt.xlabel(\"Epochs\", fontsize=\"18\")\n    plt.ylabel(\"Loss\", fontsize=\"18\")\n    plt.tick_params(axis='both', which='major', labelsize=15)\n    plt.legend(fontsize=\"15\")\n    plt.grid()\n    plt.show();\n\ndef plot_acc(train_acc, test_acc):\n    plt.plot(train_acc, label=\"Training data\")\n    plt.plot(test_acc, label=\"Validation data\")\n    plt.xlabel(\"Epochs\", fontsize=\"18\")\n    plt.ylabel(\"Accuracy\", fontsize=\"18\")\n    plt.tick_params(axis='both', which='major', labelsize=15)\n    plt.legend(fontsize=\"15\")\n    plt.grid();","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:11.926238Z","iopub.execute_input":"2023-05-16T16:39:11.926641Z","iopub.status.idle":"2023-05-16T16:39:11.934802Z","shell.execute_reply.started":"2023-05-16T16:39:11.926609Z","shell.execute_reply":"2023-05-16T16:39:11.933746Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"from torchbearer import Callback\nfrom torchbearer import callbacks\nfrom torchbearer.callbacks import MultiStepLR\n\n@callbacks.on_end_epoch\ndef callback(state):\n    try:\n        train_loss[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['loss']\n        train_acc[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['acc']\n        test_loss[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['val_loss']\n        test_acc[state[torchbearer.state.EPOCH]] = state[torchbearer.state.METRICS]['val_acc']\n    except:\n        pass","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:11.936182Z","iopub.execute_input":"2023-05-16T16:39:11.937053Z","iopub.status.idle":"2023-05-16T16:39:11.947007Z","shell.execute_reply.started":"2023-05-16T16:39:11.937021Z","shell.execute_reply":"2023-05-16T16:39:11.946034Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# train the model using cross entropy loss with loss ratio scheduler and SDG optimiser\ndef train_model(model, epochs=80):\n    model = model.to(device)\n    loss_function = nn.CrossEntropyLoss()\n    scheduler = callbacks.MultiStepLR(milestones=[40, 60], gamma=0.1)\n    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n\n    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy'], callbacks=[callback, scheduler]).to(device)\n    trial.with_generators(trainloader, test_generator=testloader, val_generator=testloader)\n    trial.run(epochs)\n    results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n    print(results)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:11.948088Z","iopub.execute_input":"2023-05-16T16:39:11.948570Z","iopub.status.idle":"2023-05-16T16:39:11.962457Z","shell.execute_reply.started":"2023-05-16T16:39:11.948539Z","shell.execute_reply":"2023-05-16T16:39:11.961520Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"num_epochs = 80\n\n# save loss and accuracy during training\ntrain_loss = np.zeros(num_epochs)\ntrain_acc = np.zeros(num_epochs)\ntest_loss = np.zeros(num_epochs)\ntest_acc = np.zeros(num_epochs)\n\n# train model\ntrain_model(model, epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:39:11.965033Z","iopub.execute_input":"2023-05-16T16:39:11.965637Z","iopub.status.idle":"2023-05-16T16:40:50.158350Z","shell.execute_reply.started":"2023-05-16T16:39:11.965599Z","shell.execute_reply":"2023-05-16T16:40:50.157276Z"},"trusted":true},"execution_count":86,"outputs":[{"output_type":"display_data","data":{"text/plain":"0/2(t):   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cdc4f2f64534ec28e9b745153c109a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0/2(v):   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b28e22497b554877b8f91bb8e239fa93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1/2(t):   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb177e5139d84234b3070d225d2c599f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1/2(v):   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b08331f7f12c4c73ae1c7a938fe83eb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0/1(e):   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba31e4612f6f43819cc08c5b97fee571"}},"metadata":{}},{"name":"stdout","text":"{'test_loss': 0.9470205307006836, 'test_acc': 0.6656000018119812}\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_loss(train_loss, test_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_acc(train_acc, test_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"./weight.weights\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References\n[1] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, and Michael Carbin. Pruning neural net- works at initialization: Why are we missing the mark? In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=Ig-VyQc-MLK","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}